{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-cors pyngrok tensorflow pillow numpy joblib --quiet"
      ],
      "metadata": {
        "id": "c4nA1qd3K4eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your auth token\n",
        "ngrok.set_auth_token(\"please paste you ngrok authtoken here \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67JoIEv8Kg7J",
        "outputId": "fa53430c-a8df-4555-9674-99f60aca4c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2BdwY4BJ8En",
        "outputId": "d55035ec-caed-4397-a79c-7ccbeca535ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ CNN model loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.8.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Admin ML model loaded\n",
            "‚úÖ Database ready\n",
            "‚úÖ Default users created\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.8.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåç PUBLIC URL: NgrokTunnel: \"https://a831-34-106-180-35.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# AI Flood Relief - Combined Backend (Citizen + Admin + Relief)\n",
        "# ==========================================\n",
        "\n",
        "!pip install flask flask-cors pyngrok tensorflow pillow numpy joblib --quiet\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "import threading, sqlite3, os, numpy as np, tensorflow as tf, joblib\n",
        "from PIL import Image\n",
        "import io\n",
        "from google.colab import drive\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Mount Drive & Paths\n",
        "# -------------------------------\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "BASE_DIR = \"/content/drive/My Drive/AI_Flood\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "DB_PATH = os.path.join(BASE_DIR, \"reports.db\")\n",
        "MODEL_PATH_H5 = os.path.join(BASE_DIR, \"flood.h5\")       # CNN model for citizen images\n",
        "MODEL_PATH_PKL = os.path.join(BASE_DIR, \"flood_model.pkl\") # Tabular ML model for admin\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Stop old processes\n",
        "# -------------------------------\n",
        "!pkill -f ngrok\n",
        "!fuser -k 5000/tcp || true\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Load models\n",
        "# -------------------------------\n",
        "# 3a. Citizen CNN model\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPool2D, UpSampling2D,\n",
        "    Dropout, BatchNormalization, Add,\n",
        "    Multiply, concatenate, Layer\n",
        ")\n",
        "\n",
        "class EncoderBlock(Layer):\n",
        "    def __init__(self, filters, rate, pooling=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.rate = rate\n",
        "        self.pooling = pooling\n",
        "        self.c1 = Conv2D(filters, 3, padding=\"same\", activation=\"relu\")\n",
        "        self.drop = Dropout(rate)\n",
        "        self.c2 = Conv2D(filters, 3, padding=\"same\", activation=\"relu\")\n",
        "        self.pool = MaxPool2D()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.c1(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.c2(x)\n",
        "        return (self.pool(x), x) if self.pooling else x\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"filters\": self.filters, \"rate\": self.rate, \"pooling\": self.pooling}\n",
        "\n",
        "class DecoderBlock(Layer):\n",
        "    def __init__(self, filters, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.rate = rate\n",
        "        self.up = UpSampling2D()\n",
        "        self.enc = EncoderBlock(filters, rate, pooling=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        x, skip = x\n",
        "        x = self.up(x)\n",
        "        x = concatenate([x, skip])\n",
        "        return self.enc(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"filters\": self.filters, \"rate\": self.rate}\n",
        "\n",
        "class AttentionGate(Layer):\n",
        "    def __init__(self, filters, bn=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.bn = bn\n",
        "        self.conv = Conv2D(filters, 3, padding=\"same\", activation=\"relu\")\n",
        "        self.down = Conv2D(filters, 3, strides=2, padding=\"same\", activation=\"relu\")\n",
        "        self.learn = Conv2D(1, 1, activation=\"sigmoid\")\n",
        "        self.up = UpSampling2D()\n",
        "        self.bn_layer = BatchNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        g, skip = x\n",
        "        x = Add()([self.conv(g), self.down(skip)])\n",
        "        x = self.learn(x)\n",
        "        x = self.up(x)\n",
        "        x = Multiply()([x, skip])\n",
        "        return self.bn_layer(x) if self.bn else x\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"filters\": self.filters, \"bn\": self.bn}\n",
        "\n",
        "# Load CNN model\n",
        "if not os.path.exists(MODEL_PATH_H5):\n",
        "    raise FileNotFoundError(\"‚ùå Citizen CNN model missing\")\n",
        "\n",
        "cnn_model = tf.keras.models.load_model(\n",
        "    MODEL_PATH_H5,\n",
        "    custom_objects={\"EncoderBlock\": EncoderBlock, \"DecoderBlock\": DecoderBlock, \"AttentionGate\": AttentionGate},\n",
        "    compile=False\n",
        ")\n",
        "print(\"‚úÖ CNN model loaded\")\n",
        "\n",
        "# Load Admin ML model\n",
        "if not os.path.exists(MODEL_PATH_PKL):\n",
        "    raise FileNotFoundError(\"‚ùå Admin ML model missing\")\n",
        "ml_model = joblib.load(MODEL_PATH_PKL)\n",
        "print(\"‚úÖ Admin ML model loaded\")\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ Initialize DB\n",
        "# -------------------------------\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "# Reports table\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS reports (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    area TEXT,\n",
        "    people_affected TEXT,\n",
        "    citizen_message TEXT,\n",
        "    flood_severity TEXT,\n",
        "    flooded_area_ratio REAL,\n",
        "    recommended_resources TEXT,\n",
        "    report_status TEXT DEFAULT 'Pending',\n",
        "    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "\"\"\")\n",
        "# Users table (role-based login)\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS users (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    username TEXT UNIQUE,\n",
        "    password TEXT,\n",
        "    role TEXT CHECK(role IN ('admin','citizen','relief'))\n",
        ")\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "conn.close()\n",
        "print(\"‚úÖ Database ready\")\n",
        "\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Insert default users (only if not exists)\n",
        "users = [\n",
        "    (\"admin\", \"admin123\", \"admin\"),\n",
        "    (\"citizen\", \"citizen123\", \"citizen\"),\n",
        "    (\"relief\", \"relief123\", \"relief\")\n",
        "]\n",
        "\n",
        "for u in users:\n",
        "    try:\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO users (username, password, role) VALUES (?, ?, ?)\",\n",
        "            u\n",
        "        )\n",
        "    except:\n",
        "        pass  # user already exists\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"‚úÖ Default users created\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5Ô∏è‚É£ Flask App\n",
        "# -------------------------------\n",
        "app = Flask(__name__)\n",
        "app.secret_key = \"supersecretkey\"\n",
        "CORS(app)\n",
        "\n",
        "# -------------------------------\n",
        "# 6Ô∏è‚É£ Helper functions\n",
        "# -------------------------------\n",
        "def preprocess_image(img_bytes):\n",
        "    img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "    img = img.resize((256,256))\n",
        "    img = np.array(img)/255.0\n",
        "    return np.expand_dims(img, axis=0)\n",
        "\n",
        "def analyze_mask(mask):\n",
        "    flooded = np.sum(mask>0.5)\n",
        "    ratio = flooded/mask.size\n",
        "    if ratio>0.6:\n",
        "        return \"Severe\", ratio, [\"Boats\",\"Food\",\"Medical\",\"Shelter\"]\n",
        "    elif ratio>0.3:\n",
        "        return \"Moderate\", ratio, [\"Food\",\"Shelter\"]\n",
        "    return \"Low\", ratio, [\"Monitoring\"]\n",
        "\n",
        "# -------------------------------\n",
        "# 7Ô∏è‚É£ Routes\n",
        "# -------------------------------\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return \"üåä AI Flood Relief Combined Backend Running\"\n",
        "\n",
        "# 7a. Login\n",
        "@app.route(\"/login\", methods=[\"POST\", \"OPTIONS\"])\n",
        "def login():\n",
        "    if request.method == \"OPTIONS\":\n",
        "        return (\"\", 204)\n",
        "\n",
        "    data = request.get_json(force=True)\n",
        "    username = data.get(\"username\")\n",
        "    password = data.get(\"password\")\n",
        "\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\n",
        "        \"SELECT role FROM users WHERE username=? AND password=?\",\n",
        "        (username, password)\n",
        "    )\n",
        "    row = cursor.fetchone()\n",
        "    conn.close()\n",
        "\n",
        "    if row:\n",
        "        return jsonify({\"success\": True, \"role\": row[0]})\n",
        "\n",
        "    return jsonify({\"success\": False, \"message\": \"Invalid credentials\"}), 401\n",
        "\n",
        "# 7b. Citizen: submit report\n",
        "@app.route(\"/report\", methods=[\"POST\"])\n",
        "def submit_report():\n",
        "    image = request.files[\"image\"]\n",
        "    text = request.form.get(\"text\",\"\")\n",
        "    area = request.form.get(\"area\",\"\")\n",
        "    people = request.form.get(\"people\",\"\")\n",
        "    img = preprocess_image(image.read())\n",
        "    pred = cnn_model.predict(img)\n",
        "    mask = np.squeeze(pred)\n",
        "    if mask.ndim==3: mask = mask.mean(axis=-1)\n",
        "    severity, ratio, resources = analyze_mask(mask)\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        INSERT INTO reports (area, people_affected, citizen_message, flood_severity, flooded_area_ratio, recommended_resources)\n",
        "        VALUES (?,?,?,?,?,?)\n",
        "    \"\"\",(area, people, text, severity, float(ratio), \",\".join(resources)))\n",
        "    conn.commit(); conn.close()\n",
        "    return jsonify({\"flood_severity\": severity,\"flooded_area_ratio\": round(float(ratio),2),\"recommended_resources\": resources})\n",
        "\n",
        "# 7c. Admin/Relief APIs\n",
        "@app.route(\"/reports\", methods=[\"GET\"])\n",
        "def get_reports():\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM reports ORDER BY timestamp DESC\")\n",
        "    rows = cursor.fetchall(); conn.close()\n",
        "    keys = [\"id\",\"area\",\"people_affected\",\"citizen_message\",\"flood_severity\",\"flooded_area_ratio\",\"recommended_resources\",\"report_status\",\"timestamp\"]\n",
        "    return jsonify([dict(zip(keys,r)) for r in rows])\n",
        "\n",
        "@app.route(\"/reports/assigned\", methods=[\"GET\"])\n",
        "def get_assigned_reports():\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM reports WHERE UPPER(TRIM(report_status))='ASSIGNED' ORDER BY timestamp DESC\")\n",
        "    rows = cursor.fetchall(); conn.close()\n",
        "    keys = [\"id\",\"area\",\"people_affected\",\"citizen_message\",\"flood_severity\",\"flooded_area_ratio\",\"recommended_resources\",\"report_status\",\"timestamp\"]\n",
        "    return jsonify([dict(zip(keys,r)) for r in rows])\n",
        "\n",
        "@app.route(\"/reports/update\", methods=[\"POST\"])\n",
        "def update_report():\n",
        "    data = request.get_json(force=True)\n",
        "    report_id = data.get(\"id\")\n",
        "    status = data.get(\"status\")\n",
        "    if not report_id or not status: return jsonify({\"success\":False,\"message\":\"Missing id/status\"}),400\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"UPDATE reports SET report_status=? WHERE id=?\",(status.strip(), report_id))\n",
        "    conn.commit(); conn.close()\n",
        "    return jsonify({\"success\":True,\"message\":\"Report updated\"})\n",
        "\n",
        "# 7d. Admin: Predict flood (tabular)\n",
        "@app.route(\"/predict-flood\", methods=[\"POST\"])\n",
        "def predict_flood():\n",
        "    data = request.json.get(\"features\")\n",
        "    if not data or len(data)!=20:\n",
        "        return jsonify({\"error\":\"Exactly 20 features required\"}),400\n",
        "    features = np.array(data).reshape(1,-1)\n",
        "    prediction = ml_model.predict(features)[0]\n",
        "    if prediction<0.3: risk=\"Low\"\n",
        "    elif prediction<0.6: risk=\"Moderate\"\n",
        "    else: risk=\"High\"\n",
        "    return jsonify({\"flood_probability\": round(float(prediction),3),\"risk_level\": risk})\n",
        "\n",
        "# -------------------------------\n",
        "# 8Ô∏è‚É£ Run server & ngrok\n",
        "# -------------------------------\n",
        "def run():\n",
        "    app.run(host=\"0.0.0.0\", port=5000, debug=False)\n",
        "\n",
        "threading.Thread(target=run).start()\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"üåç PUBLIC URL:\", public_url)\n",
        "\n",
        "\n"
      ]
    }
  ]
}